version: '3'

services:
  zooV2:
    image: zookeeper:3.4.9
    hostname: zooV2
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zooV2:2888:3888
    volumes:
      - "../zk-kafka/zooV2/data:/data:rw"
      - "../zk-kafka/zooV2/datalog:/datalog:rw"
  kafkaV21:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafkaV21
    links:
      - zooV2
    environment:
      HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"
      KAFKA_BROKER_ID: 1
      KAFKA_REPLICATION_FACTOR: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_ZOOKEEPER_CONNECT: "zooV2:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafkaV21:9092,CONNECTIONS_FROM_HOST://localhost:19091
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - "../zk-kafka/kafkaV21/data:/var/lib/kafka/data:rw"
  kafkaV22:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafkaV22
    links:
      - zooV2
    environment:
      KAFKA_REPLICATION_FACTOR: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: "zooV2:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafkaV22:9092,CONNECTIONS_FROM_HOST://localhost:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - "../zk-kafka/kafkaV22/data:/var/lib/kafka/data:rw"
  kafkaV23:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafkaV23
    links:
      - zooV2
    environment:
      KAFKA_REPLICATION_FACTOR: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_BROKER_ID: 3
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafkaV23:9092,CONNECTIONS_FROM_HOST://localhost:19093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: "zooV2:2181"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - "../zk-kafka/kafkaV23/data:/var/lib/kafka/data:rw"
  postgresV2:
    image: postgres:11-alpine
    hostname: postgresV2
    shm_size: 4g
    ports: [ 5433:5432 ]
    environment:
      POSTGRES_PASSWORD: Ccv4dX#_Fq7bSsFf
    volumes:
      - "${PWD}/postgres:/var/lib/postgresql/data:rw"
  indexer:
    build:
      context: /data/ergoAnalyticsV2/ergo-analytics/modules/indexer/target/docker/stage
      dockerfile: Dockerfile
    volumes:
      - "${PWD}/conf/indexer.conf:/etc/indexer.conf"
      - "${PWD}/logs:/var/log/analytics:rw"
    command: /etc/indexer.conf
    depends_on:
      - kafkaV21
      - kafkaV22
      - kafkaV23
      - postgresV2
    logging:
      options:
        max-size: "10m"
        max-file: "10"
  redisV2:
    image: redis:latest
    hostname: redisV2
    restart: always
    command: ["redis-server"]
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - "../redis:/data"
  tracker:
    image: tracker-v2:latest
    volumes:
      - "${PWD}/conf/tracker.yml:/etc/config.yml:ro"
      - "${PWD}/conf/log4rs.yaml:/etc/log4rs.yaml:ro"
    #command: /usr/config.yml
    depends_on:
      - kafkaV21
    logging:
      options:
        max-size: "10m"
        max-file: "10"